{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"liver_disease_dataset.csv\")  # Replace with actual dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AST (SGOT)</th>\n",
       "      <th>ALT (SGPT)</th>\n",
       "      <th>AST:ALT Ratio</th>\n",
       "      <th>GGTP</th>\n",
       "      <th>ALP</th>\n",
       "      <th>Bilirubin Total</th>\n",
       "      <th>Bilirubin Direct</th>\n",
       "      <th>Bilirubin Indirect</th>\n",
       "      <th>Total Protein</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>A:G Ratio</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>Female</td>\n",
       "      <td>139</td>\n",
       "      <td>245</td>\n",
       "      <td>0.567347</td>\n",
       "      <td>466</td>\n",
       "      <td>261</td>\n",
       "      <td>3.528115</td>\n",
       "      <td>0.847263</td>\n",
       "      <td>2.680853</td>\n",
       "      <td>7.385806</td>\n",
       "      <td>4.579157</td>\n",
       "      <td>1.631533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>432</td>\n",
       "      <td>267</td>\n",
       "      <td>0.946800</td>\n",
       "      <td>0.113197</td>\n",
       "      <td>0.833603</td>\n",
       "      <td>7.424992</td>\n",
       "      <td>2.602252</td>\n",
       "      <td>0.539578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>Male</td>\n",
       "      <td>288</td>\n",
       "      <td>110</td>\n",
       "      <td>2.618182</td>\n",
       "      <td>109</td>\n",
       "      <td>149</td>\n",
       "      <td>3.033669</td>\n",
       "      <td>0.324436</td>\n",
       "      <td>2.709233</td>\n",
       "      <td>5.060133</td>\n",
       "      <td>3.652672</td>\n",
       "      <td>2.595202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>260</td>\n",
       "      <td>114</td>\n",
       "      <td>2.280702</td>\n",
       "      <td>412</td>\n",
       "      <td>136</td>\n",
       "      <td>1.459950</td>\n",
       "      <td>0.403953</td>\n",
       "      <td>1.055996</td>\n",
       "      <td>5.500904</td>\n",
       "      <td>5.460975</td>\n",
       "      <td>136.735229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>259</td>\n",
       "      <td>0.069498</td>\n",
       "      <td>585</td>\n",
       "      <td>279</td>\n",
       "      <td>4.726851</td>\n",
       "      <td>0.933136</td>\n",
       "      <td>3.793715</td>\n",
       "      <td>5.946073</td>\n",
       "      <td>4.252944</td>\n",
       "      <td>2.511869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex  AST (SGOT)  ALT (SGPT)  AST:ALT Ratio  GGTP  ALP  \\\n",
       "0   71  Female         139         245       0.567347   466  261   \n",
       "1   34  Female          32         200       0.160000   432  267   \n",
       "2   80    Male         288         110       2.618182   109  149   \n",
       "3   40  Female         260         114       2.280702   412  136   \n",
       "4   43    Male          18         259       0.069498   585  279   \n",
       "\n",
       "   Bilirubin Total  Bilirubin Direct  Bilirubin Indirect  Total Protein  \\\n",
       "0         3.528115          0.847263            2.680853       7.385806   \n",
       "1         0.946800          0.113197            0.833603       7.424992   \n",
       "2         3.033669          0.324436            2.709233       5.060133   \n",
       "3         1.459950          0.403953            1.055996       5.500904   \n",
       "4         4.726851          0.933136            3.793715       5.946073   \n",
       "\n",
       "    Albumin   A:G Ratio  Condition  \n",
       "0  4.579157    1.631533          0  \n",
       "1  2.602252    0.539578          0  \n",
       "2  3.652672    2.595202          4  \n",
       "3  5.460975  136.735229          0  \n",
       "4  4.252944    2.511869          0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical column 'Sex'\n",
    "label_encoder = LabelEncoder()\n",
    "data['Sex'] = label_encoder.fit_transform(data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AST (SGOT)</th>\n",
       "      <th>ALT (SGPT)</th>\n",
       "      <th>AST:ALT Ratio</th>\n",
       "      <th>GGTP</th>\n",
       "      <th>ALP</th>\n",
       "      <th>Bilirubin Total</th>\n",
       "      <th>Bilirubin Direct</th>\n",
       "      <th>Bilirubin Indirect</th>\n",
       "      <th>Total Protein</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>A:G Ratio</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>245</td>\n",
       "      <td>0.567347</td>\n",
       "      <td>466</td>\n",
       "      <td>261</td>\n",
       "      <td>3.528115</td>\n",
       "      <td>0.847263</td>\n",
       "      <td>2.680853</td>\n",
       "      <td>7.385806</td>\n",
       "      <td>4.579157</td>\n",
       "      <td>1.631533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>432</td>\n",
       "      <td>267</td>\n",
       "      <td>0.946800</td>\n",
       "      <td>0.113197</td>\n",
       "      <td>0.833603</td>\n",
       "      <td>7.424992</td>\n",
       "      <td>2.602252</td>\n",
       "      <td>0.539578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>110</td>\n",
       "      <td>2.618182</td>\n",
       "      <td>109</td>\n",
       "      <td>149</td>\n",
       "      <td>3.033669</td>\n",
       "      <td>0.324436</td>\n",
       "      <td>2.709233</td>\n",
       "      <td>5.060133</td>\n",
       "      <td>3.652672</td>\n",
       "      <td>2.595202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>114</td>\n",
       "      <td>2.280702</td>\n",
       "      <td>412</td>\n",
       "      <td>136</td>\n",
       "      <td>1.459950</td>\n",
       "      <td>0.403953</td>\n",
       "      <td>1.055996</td>\n",
       "      <td>5.500904</td>\n",
       "      <td>5.460975</td>\n",
       "      <td>136.735229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>259</td>\n",
       "      <td>0.069498</td>\n",
       "      <td>585</td>\n",
       "      <td>279</td>\n",
       "      <td>4.726851</td>\n",
       "      <td>0.933136</td>\n",
       "      <td>3.793715</td>\n",
       "      <td>5.946073</td>\n",
       "      <td>4.252944</td>\n",
       "      <td>2.511869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  AST (SGOT)  ALT (SGPT)  AST:ALT Ratio  GGTP  ALP  \\\n",
       "0   71    0         139         245       0.567347   466  261   \n",
       "1   34    0          32         200       0.160000   432  267   \n",
       "2   80    1         288         110       2.618182   109  149   \n",
       "3   40    0         260         114       2.280702   412  136   \n",
       "4   43    1          18         259       0.069498   585  279   \n",
       "\n",
       "   Bilirubin Total  Bilirubin Direct  Bilirubin Indirect  Total Protein  \\\n",
       "0         3.528115          0.847263            2.680853       7.385806   \n",
       "1         0.946800          0.113197            0.833603       7.424992   \n",
       "2         3.033669          0.324436            2.709233       5.060133   \n",
       "3         1.459950          0.403953            1.055996       5.500904   \n",
       "4         4.726851          0.933136            3.793715       5.946073   \n",
       "\n",
       "    Albumin   A:G Ratio  Condition  \n",
       "0  4.579157    1.631533          0  \n",
       "1  2.602252    0.539578          0  \n",
       "2  3.652672    2.595202          4  \n",
       "3  5.460975  136.735229          0  \n",
       "4  4.252944    2.511869          0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['GGTP', 'ALP', 'Bilirubin Total']] = np.log1p(data[['GGTP', 'ALP', 'Bilirubin Total']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "X = data.drop(columns=['Condition'])\n",
    "y = data['Condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape input for LSTM (samples, time steps, features)\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to categorical\n",
    "num_classes = len(np.unique(y))\n",
    "y_categorical = to_categorical(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(1, X.shape[1])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 4s 9ms/step - loss: 1.5274 - accuracy: 0.4058 - val_loss: 1.4734 - val_accuracy: 0.4210\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4846 - accuracy: 0.4075 - val_loss: 1.4747 - val_accuracy: 0.4210\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4872 - accuracy: 0.4075 - val_loss: 1.4742 - val_accuracy: 0.4210\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4844 - accuracy: 0.4075 - val_loss: 1.4752 - val_accuracy: 0.4210\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4853 - accuracy: 0.4075 - val_loss: 1.4745 - val_accuracy: 0.4210\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4845 - accuracy: 0.4075 - val_loss: 1.4747 - val_accuracy: 0.4210\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4840 - accuracy: 0.4075 - val_loss: 1.4769 - val_accuracy: 0.4210\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4850 - accuracy: 0.4075 - val_loss: 1.4805 - val_accuracy: 0.4210\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4847 - accuracy: 0.4075 - val_loss: 1.4767 - val_accuracy: 0.4210\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4844 - accuracy: 0.4075 - val_loss: 1.4765 - val_accuracy: 0.4210\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4841 - accuracy: 0.4075 - val_loss: 1.4781 - val_accuracy: 0.4210\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4834 - accuracy: 0.4075 - val_loss: 1.4775 - val_accuracy: 0.4210\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4822 - accuracy: 0.4075 - val_loss: 1.4776 - val_accuracy: 0.4210\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4832 - accuracy: 0.4075 - val_loss: 1.4777 - val_accuracy: 0.4210\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4821 - accuracy: 0.4075 - val_loss: 1.4782 - val_accuracy: 0.4210\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4821 - accuracy: 0.4075 - val_loss: 1.4783 - val_accuracy: 0.4210\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4827 - accuracy: 0.4075 - val_loss: 1.4776 - val_accuracy: 0.4210\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 1.4833 - accuracy: 0.4075 - val_loss: 1.4776 - val_accuracy: 0.4210\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4832 - accuracy: 0.4075 - val_loss: 1.4792 - val_accuracy: 0.4210\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4830 - accuracy: 0.4075 - val_loss: 1.4778 - val_accuracy: 0.4210\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 1.4824 - accuracy: 0.4075 - val_loss: 1.4782 - val_accuracy: 0.4210\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4820 - accuracy: 0.4075 - val_loss: 1.4780 - val_accuracy: 0.4210\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4820 - accuracy: 0.4075 - val_loss: 1.4782 - val_accuracy: 0.4210\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4823 - accuracy: 0.4075 - val_loss: 1.4786 - val_accuracy: 0.4210\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4828 - accuracy: 0.4075 - val_loss: 1.4791 - val_accuracy: 0.4210\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4818 - accuracy: 0.4075 - val_loss: 1.4794 - val_accuracy: 0.4210\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4819 - accuracy: 0.4075 - val_loss: 1.4786 - val_accuracy: 0.4210\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4816 - accuracy: 0.4075 - val_loss: 1.4788 - val_accuracy: 0.4210\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4825 - accuracy: 0.4075 - val_loss: 1.4791 - val_accuracy: 0.4210\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4808 - accuracy: 0.4075 - val_loss: 1.4800 - val_accuracy: 0.4210\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4827 - accuracy: 0.4075 - val_loss: 1.4785 - val_accuracy: 0.4210\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4810 - accuracy: 0.4075 - val_loss: 1.4793 - val_accuracy: 0.4210\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4816 - accuracy: 0.4075 - val_loss: 1.4787 - val_accuracy: 0.4210\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4813 - accuracy: 0.4075 - val_loss: 1.4783 - val_accuracy: 0.4210\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4820 - accuracy: 0.4075 - val_loss: 1.4786 - val_accuracy: 0.4210\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4815 - accuracy: 0.4075 - val_loss: 1.4789 - val_accuracy: 0.4210\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4816 - accuracy: 0.4075 - val_loss: 1.4789 - val_accuracy: 0.4210\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4806 - accuracy: 0.4075 - val_loss: 1.4790 - val_accuracy: 0.4210\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4812 - accuracy: 0.4075 - val_loss: 1.4792 - val_accuracy: 0.4210\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4814 - accuracy: 0.4075 - val_loss: 1.4793 - val_accuracy: 0.4210\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4819 - accuracy: 0.4075 - val_loss: 1.4791 - val_accuracy: 0.4210\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4813 - accuracy: 0.4075 - val_loss: 1.4797 - val_accuracy: 0.4210\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4822 - accuracy: 0.4075 - val_loss: 1.4796 - val_accuracy: 0.4210\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4817 - accuracy: 0.4075 - val_loss: 1.4793 - val_accuracy: 0.4210\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4806 - accuracy: 0.4075 - val_loss: 1.4797 - val_accuracy: 0.4210\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4810 - accuracy: 0.4075 - val_loss: 1.4829 - val_accuracy: 0.4210\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4813 - accuracy: 0.4075 - val_loss: 1.4808 - val_accuracy: 0.4210\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4818 - accuracy: 0.4075 - val_loss: 1.4804 - val_accuracy: 0.4210\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4813 - accuracy: 0.4075 - val_loss: 1.4793 - val_accuracy: 0.4210\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.4818 - accuracy: 0.4075 - val_loss: 1.4801 - val_accuracy: 0.4210\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4801 - accuracy: 0.4210\n",
      "Test Accuracy: 42.10%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
